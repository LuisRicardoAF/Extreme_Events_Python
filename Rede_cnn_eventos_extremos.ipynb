{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construindo o modelo Keras para Redes Neurais Convolutivas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importações\n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "from sklearn.datasets import load_sample_images\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from skimage.feature import hog\n",
    "import skimage\n",
    "from skimage.io import imread\n",
    "from skimage.transform import rescale\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "from skimage import data, color\n",
    "from skimage.feature import hog\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Ferramenta Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A ferramenta Keras é um framework desenvolvido em linguagem de programação Python que\n",
    "suporta o desenvolvimento de modelos de Deep Learning.\n",
    "\n",
    "O framework Keras (CHOLLET et al., 2015) é uma ferramenta para o desenvolvimento\n",
    "de redes neurais profundas, contendo bibliotecas e métodos para cada um dos tipos\n",
    "de redes descritas na literatura.\n",
    "Estas redes podem ser programadas tanto em linguagem Python como em Linguagem R, pois o framework dá suporte a estas diferentes linguagens. A biblioteca é\n",
    "aplicável nas seguintes condições:\n",
    "- a) Prototipagem rápida e fácil (total modularidade, minimalismo e extensibilidade),\n",
    "- b) Suporte a redes convolucionais e recorrentes, incluindo combinação de ambas,\n",
    "- c) Suporte a esquemas de conectividade arbitrária (incluindo treino de N para N).\n",
    "- d) Execução em CPU ou GPU.\n",
    "\n",
    "Os modelos em Keras são definidos como uma sequência de camadas distintas em\n",
    "redes neurais. Isto facilita a criação do modelo, bastando inserir uma camada por\n",
    "vez até que estejamos satisfeitos com a topologia da rede. Primeiro, define-se a\n",
    "camada de entrada com as dimensões corretas, como matrizes das imagens e vetores\n",
    "de caracteristicas. Existe uma questão muito difícil a considerar, que é o número de\n",
    "camadas e seus tipos. O Keras premite o uso de um método heurístico para encontrar\n",
    "a melhor estrutura de rede, mas este algoritmo é custoso computacionalmente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acesso aos dados\n",
    "\n",
    "Os dados obtidos nos produtos HURSAT e GOES são especificamente dados matriciais. As imagens de eventos extremos correspondem a matrizes de 300x300 pixeis (ajuste padrão). Estas matrizes foram inseridas em uma tabela (Dataframe) para facilitar o acesso aos dados. Neste trabalho os Dataframes dividem as imagens em Eventos e Não-Eventos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "caminhoDataframe = \"C:\\/Users\\/Administrador\\/Desktop\\/App Python\\/\"\n",
    "\n",
    "def abreDataFrame(caminho,nomeArq):\n",
    "    dataFrame = pd.read_pickle(caminho + nomeArq)#READ PICKLE MUITO IMPORTANTE!!!!!\n",
    "    return dataFrame\n",
    "\n",
    "df1 = abreDataFrame(caminhoDataframe, 'Data_Frame_EVENTO.pkl')\n",
    "df2 = abreDataFrame(caminhoDataframe, 'Data_Frame_N_EVENTO.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Array_IMG</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[0.30812746], [0.33844912], [0.34922633], [0...</td>\n",
       "      <td>Evento</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[0.30812746], [0.33844912], [0.34922633], [0...</td>\n",
       "      <td>Evento</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[0.6184512], [0.6798183], [0.66341066], [0.6...</td>\n",
       "      <td>Evento</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[[0.37978172], [0.39215672], [0.39215672], [0...</td>\n",
       "      <td>Evento</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[[0.30333334], [0.30333334], [0.30190587], [0...</td>\n",
       "      <td>Evento</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Array_IMG   Label\n",
       "0  [[[0.30812746], [0.33844912], [0.34922633], [0...  Evento\n",
       "1  [[[0.30812746], [0.33844912], [0.34922633], [0...  Evento\n",
       "2  [[[0.6184512], [0.6798183], [0.66341066], [0.6...  Evento\n",
       "3  [[[0.37978172], [0.39215672], [0.39215672], [0...  Evento\n",
       "4  [[[0.30333334], [0.30333334], [0.30190587], [0...  Evento"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Array_IMG</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[0.15353093], [0.2007128], [0.1698009], [0.1...</td>\n",
       "      <td>N_Evento</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[0.15353093], [0.2007128], [0.1698009], [0.1...</td>\n",
       "      <td>N_Evento</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[0.056682266], [0.059096612], [0.059714362],...</td>\n",
       "      <td>N_Evento</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[[0.059946757], [0.06290987], [0.06290987], [...</td>\n",
       "      <td>N_Evento</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[[0.06433763], [0.076096654], [0.08731399], [...</td>\n",
       "      <td>N_Evento</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Array_IMG     Label\n",
       "0  [[[0.15353093], [0.2007128], [0.1698009], [0.1...  N_Evento\n",
       "1  [[[0.15353093], [0.2007128], [0.1698009], [0.1...  N_Evento\n",
       "2  [[[0.056682266], [0.059096612], [0.059714362],...  N_Evento\n",
       "3  [[[0.059946757], [0.06290987], [0.06290987], [...  N_Evento\n",
       "4  [[[0.06433763], [0.076096654], [0.08731399], [...  N_Evento"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotulando as matrizes para corresponder aos objetos\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "DADOS DA REDE NEURAL\n",
    "'''\n",
    "#ROTULANDO\n",
    "def machine_learning_tag(dataframe):\n",
    "    \n",
    "    nome_valor = []\n",
    "    for i in range(len(dataframe.index)):\n",
    "        if(dataframe.loc[i,'Label'] == 'Evento'):\n",
    "            valor = 1\n",
    "            nome_valor.append(valor)\n",
    "        elif(dataframe.loc[i,'Label'] == 'N_Evento'):\n",
    "            valor = 0\n",
    "            nome_valor.append(valor)\n",
    "            \n",
    "    dataframe['Tag_valor'] = nome_valor     \n",
    "    \n",
    "    return nome_valor\n",
    "\n",
    "#Concatenar os DataFrames\n",
    "CME_frames = [df1, df2]\n",
    "dataFrame_CME = pd.concat(CME_frames)\n",
    "#RESET INDEX -- 0,1,2,3,4, ... , N\n",
    "dataFrame_CME = dataFrame_CME.reset_index(drop=True)\n",
    "\n",
    "\n",
    "#Rotulando dados\n",
    "#labels\n",
    "nome_tag = machine_learning_tag(dataFrame_CME)\n",
    "vetor_nome_tag = np.array(nome_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividindo os conjuntos de dados\n",
    "\n",
    "A forma comum desta divisão do conjuntos de dados\n",
    "obedece classicamente às seguintes proporções:\n",
    "\n",
    "- a) Conjuntos de Treinamento: Correspondem a 80%, 66% ou 60% da amostra total de dados.\n",
    "\n",
    "- b) Conjuntos de Teste e Validação: Correspondem a 20%, 33% ou 40% da amostra de dados quando não é necessário um conjunto de validação. Quando um conjunto de validação está presente o conjunto de teste pode corresponder à 10%, 15% ou 20% da amostra original. A tanto a validação quanto o teste não são submetidos ao modelo.\n",
    "\n",
    "Esta forma de divisão dos dados de entrada propicia um cenário em que mesmo que\n",
    "a convergência (aproximação de uma solução ótima) da RNA esteja em um nível\n",
    "próximo ao mínimo ou máximo global, a resposta, ou seja, os testes e validações da\n",
    "rede são executados em conjuntos com 80% menos dados do que a amostra original. Esta característica remove a representatividade da análise, sendo necessária a aplicação direta da rede para dados recém-coletados ou de outras bases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1272,)\n"
     ]
    }
   ],
   "source": [
    "#Dividindo Conjunto de treinamento e de Teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    dataFrame_CME.loc[:,'Array_IMG'],\n",
    "    vetor_nome_tag,\n",
    "    test_size=0.3,\n",
    "    shuffle=True,\n",
    "    random_state=42,\n",
    ")\n",
    "print(X_train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construindo modelo de Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salvando os resultados e o modelo de treinamento da rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "SALVANDO DICIONÁRIOS DE VALORES DOS TREINOS\n",
    "'''\n",
    "def salvaDicionarios(dicionarios,caminhoSaida,nomeArquivo):\n",
    "    np.save(caminhoSaida+'\\/'+nomeArquivo,dicionarios)\n",
    "\n",
    "def carregaDicionarios(caminhoSaida,nomeArquivo):\n",
    "    dicionarios = np.load(caminhoSaida+'\\/'+nomeArquivo).item()\n",
    "    return dicionarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reshape das matrizes para se adequar às entradas da redes neurais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Ajusta vetores\n",
    "'''\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "\n",
    "X_train = X_train.tolist()\n",
    "X_test = X_test.tolist()\n",
    "\n",
    "X_train = np.asarray(X_train)\n",
    "X_test = np.asarray(X_test)\n",
    "\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "REDE CONVOLUTIVA - ARQUITETURA 1\n",
    "'''\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "model2 = models.Sequential()\n",
    "model2.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(300, 300, 1)))\n",
    "model2.add(layers.MaxPooling2D((2, 2)))\n",
    "model2.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model2.add(layers.MaxPooling2D((2, 2)))\n",
    "model2.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "model2.add(layers.Flatten())\n",
    "model2.add(layers.Dense(64, activation='relu'))\n",
    "model2.add(layers.Dense(2, activation='softmax'))\n",
    "\n",
    "model2.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model2.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test))\n",
    "\n",
    "test_loss, test_acc = model2.evaluate(X_test, y_test)\n",
    "print('test_acc:', test_acc)\n",
    "\n",
    "\n",
    "#cria dicionario\n",
    "history_dict = history.history\n",
    "history_dict.keys()\n",
    "\n",
    "\n",
    "import numpy\n",
    "loss_history = history.history[\"loss\"]\n",
    "numpy_loss_history = numpy.array(loss_history)\n",
    "numpy.savetxt(\"loss_history_Rede_Convolutiva_CME.txt\", numpy_loss_history, delimiter=\",\")\n",
    "\n",
    "#salva dicionário\n",
    "salvaDicionarios(history_dict,caminhoDataframe,'Rede_Neural_Convolutiva_Extremos'+'.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salvando o modelo treinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# SALVANDO O MODELO\n",
    "filename = \"ARQ1_CONVNET_Extremos\"+'.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "import pickle\n",
    "def carregaModelo(nomeModelo):\n",
    "    carrega_modelo = pickle.load(open(nomeModelo+'.sav', 'rb'))\n",
    "    return carrega_modelo\n",
    "\n",
    "\n",
    "model = carregaModelo(\"ARQ1_CONVNET_Extremos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = carregaDicionarios(caminhoDataframe, 'Rede_Neural_Convolutiva_Extremos.npy')\n",
    "\n",
    "acc = history['acc']\n",
    "val_acc = history['val_acc']\n",
    "loss = history['loss']\n",
    "val_loss = history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc,'k', label='Acuracia no Treinamento')\n",
    "plt.plot(epochs, val_acc, 'b', label='Acuracia no Teste')\n",
    "plt.title('Acurácia no Treinamento e no Teste')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss,'k', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Test loss')\n",
    "plt.title('Erro no Treinamento e no Teste')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "acc_values = history['acc']\n",
    "val_acc_values = history['val_acc']\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc_values, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gerando Matriz de Confusão\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_prediction = model.predict(X_test)\n",
    "# Convert predictions classes to one hot vectors \n",
    "Y_pred_classes = np.argmax(Y_prediction,axis = 1) \n",
    "# Convert validation observations to one hot vectors\n",
    "Y_true = np.argmax(y_test,axis = 1) \n",
    "# compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(confusion_mtx, annot=True, fmt=\"d\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gerando Ativação das Camadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "A ativação das Camadas e suas Imagens - Resposta do Que a Rede Abstrai no decorrer\n",
    "dos Treinamentos.\n",
    "'''\n",
    "from keras.models import Model\n",
    "layer_outputs = [layer.output for layer in model.layers]\n",
    "activation_model = Model(inputs=model.input, outputs=layer_outputs)\n",
    "activations = activation_model.predict(X2[620].reshape(1,300, 300,1))\n",
    " \n",
    "def display_activation(activations, col_size, row_size, act_index): \n",
    "    activation = activations[act_index]\n",
    "    activation_index=0\n",
    "    fig, ax = plt.subplots(row_size, col_size, figsize=(row_size*2.5,col_size*1.5))\n",
    "    for row in range(0,row_size):\n",
    "        for col in range(0,col_size):\n",
    "            ax[row][col].imshow(activation[0, :, :, activation_index])\n",
    "            activation_index += 1\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(X2[620][:,:,0]);\n",
    "\n",
    "display_activation(activations, 5, 4, 1)\n",
    "\n",
    "display_activation(activations, 5, 4, 2)\n",
    "\n",
    "display_activation(activations, 5, 4, 3)\n",
    "\n",
    "display_activation(activations, 5, 4, 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
